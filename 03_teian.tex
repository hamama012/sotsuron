\chapter{提案手法}
本章では，本研究で開発するバーチャルペットについて述べる．

\section{概要}

%更に、コントローラの振動機能を利用し、ユーザとバーチャルペットが接触した際に振動を起こすことで、触覚再現とまではいかずとも触ったという感覚をユーザに返すことができる。

%また、HMDを利用するとユーザの視界から現実の物や環境が遮断されることから、仮想空間内の環境もユーザに大きな影響を与えることが推測される。これはVRを利用するバーチャルペットのみに発生する特性であり、セラピー効果に関連することが考えられる。この仮想空間内の環境は開発側が任意に変更できることから、仮想空間の自由性として考える。

本研究のシステム構成図を\ref{fig:system}に示す。
本システムはHTC Vive、コントローラ、ヘッドホンから成るデバイス部とUnityにより実装したペットシステム部から構成される。

\begin{figure}[H]
\centering
\includegraphics*[width=12cm,clip]{images/提案手法図.eps}
\caption{提案システムの構成}
\label{fig:system}
\end{figure}

ユーザはHTC Vive、イヤホンを装着し、コントローラを手に持った状態で仮想空間に没入する。
仮想空間にはペットとユーザの２つのアバターと、環境オブジェクトが存在する。ユーザの頭部の方向はHTC Viveに、手の動きはコントローラによってトラッキングされ、仮想空間上に反映される。コントローラはトリガーもしくはボタンが入力されれば、その情報をユーザ管理プログラムへと渡す。
ユーザアバターがペットアバターとの衝突を検知すると、ユーザ管理プログラムとペット管理プログラムへそれぞれ衝突情報が渡される。ユーザ管理プログラムからはコントローラへ振動命令が出され、コントローラが振動することでユーザに接触フィードバックを起こす。
ペット管理プログラムはペットアバターのアニメーションの１つである尻尾を振る動作の再生を行い、喜びを表現する。

システムを起動すると、ペットが自由に動き回る待機状態から開始する。ユーザがトリガーを深く引くと、ペットはユーザの位置まで移動し、ユーザの手前で停止する。この状態を触れ合い可能状態と呼ぶ。触れ合い可能状態では、ペットに触れることが可能になる。
この状態で再度トリガーを深く引くと、ペットは待機状態へと戻りフィールド内を自由に歩き回るようになる。

\begin{figure}[H]
\centering
\includegraphics*[width=16cm,clip]{images/chart1.eps}
\caption{ペットの動作のフローチャート}
\label{fig:chart1}
\end{figure} 

\subsection{仮想空間}

仮想空間の構築にはUnityを使用した。仮想空間を構成するオブジェクトの一覧を表\ref{table:objectList}に示す。

\begin{table}[H]
\centering
\caption{オブジェクト一覧}
\label{table:objectList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|r|}
\hline
名前 & 説明 \\
\hline
Directional light	& ライト \\
Pet				& ペットアバター \\
CameraRig		& カメラ（子オブジェクトにユーザアバターを含む） \\
BackGround		& 背景オブジェクト\\
FaceComplition	& ペットアバターの視線補完オブジェクト \\
SteamVR		& SteamVRプラグイン\\
\hline 
\end{tabular}}
\end{table}

BackGroundオブジェクトには環境を構成するオブジェクトを全て格納している。
木や草といったオブジェクトはUnityのアセットストアで入手したNature Starter Kit 2を使用した。
更に、風を吹かせることができるWindZoneオブジェクトを配置することで、木の葉や草が揺らすように表現した。
環境音は木々のざわめきと鳥のさえずりの二種類を用意し、音量を調整した上で同時に再生した。音はループ再生する。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/sc8.eps}
\caption{仮想空間}
\label{fig:vr}
\end{figure} 

\subsection{ユーザ}

仮想空間に置かれるユーザのアバターは手部分のみである。HTC Viveのコントローラにはコントローラの3DCGモデルが標準で用意されているが、現実感の付与を目的とした本研究ではコントローラよりも人間の手のモデルを使用した方が自然である。よって、Mayaを用いて手の3DCGを作成し、コントローラモデルの代わりに使用する。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/hand.eps}
\caption{ユーザの手のアバター}
\label{fig:hand}
\end{figure} 

\subsection{バーチャルペット}

本研究では先行研究のバーチャルペットは使用せず、新しく柴犬を参考にMayaを用いて3DCGモデルを作成、使用した。待機、歩く、走る、尻尾を振るの４種類のアニメーションが可能である。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/pet.eps}
\caption{バーチャルペットのアバター}
\label{fig:pet}
\end{figure} 

\section{ユーザ管理部}

ユーザ管理部はPlayerControllerとHandControllerの２つのスクリプト及びSteamVRプラグインによって構成される。この設計を以下の図に示す。

HTC Vive及びコントローラの位置情報をSteamVRプラグインを利用して取得し、各ボタンの入力に応じた動作処理はPlayerControllerで行う。
コントローラのトリガーが深く引かれると、口笛の効果音を鳴らし終えた後クラス変数の代入を行う。このクラス変数の値に応じてペット管理プログラムはペットの動作処理を実行する。
コントローラのメニューボタンが押された場合はHMDの着席位置をリセットし、グリップボタンを押された場合はシーンを切り替える。このシーンの切り替えは後述する実験で使用する。
HandControllerはControllerの子オブジェクトであるHandにアタッチされており、ペットアバターと衝突するとその情報を親オブジェクトであるPlayerControllerに渡す。衝突を検知するコライダーはSABoneColliderBuilderで作成した。
衝突情報を受け取ったPlayerControllerは、コントローラに振動命令を出す。HTC Viveのコントローラの振動の値は最大3999まで設定が可能だが、本研究で想定するペットに触れるという動作において強い振動は好ましくない。よって、人が振動を感知できる程度の弱い振動を求め値を200で実装した。

\begin{table}[H]
\centering
\caption{コントローラの入力一覧}
\label{table:userList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|l|}
\hline
入力 &　動作 \\
\hline
トリガーを深く引く & 待機状態と触れ合い可能状態への遷移 \\
メニューボタンを押す & 着席位置のリセット \\
グリップボタンを押す & シーンの切り替え \\
\hline 
\end{tabular}}
\end{table}

\section{ペット管理部}

ペット管理部はPetController、MovePet、HeadLookController、DirectionManagerの４つのスクリプトによって構成される。この設計を以下の図に示す。

PetControllerは主にペットの動作全般の制御を行う。PlayerControllerでユーザの動作に応じて代入した変数を参照し、また仮想空間の状況に応じて移動、回転、視線移動、アニメーションの再生及び停止とぺットの動作を制御する。
MovePetは待機状態におけるペットの動作を制御する。待機状態でペットはまず目標位置を設定しそこへ移動を開始する。その後一定距離移動するごとに目標位置を再設定し、その位置に移動と目標位置の設定と移動を繰り返す。触れ合い状態に移行するとき、MovePetは停止する。再び待機状態に戻る際にはまた動作を再開する。
HeadLookControllerはアセットストアから入手したスクリプトで、動かしたい部分のボーンを指定してその部分のみを空間内の指定されたターゲットに振り向くように動動かす。本研究ではペットアバターの首から頭にかけてのボーンを指定し動作させる。
DirectionManagerはペットの視線移動を補完するためのオブジェクトであるFaceComplitionの動作を制御する。
FaceComplitionの初期位置はカメラで、これに追従して動く。ユーザとペットが衝突すると、視線先ターゲットをFaceComplitionに変更し、FaceComplitionはユーザアバターの位置へと移動を開始する。
FaceComplitionがユーザアバターに衝突すると、視線先ターゲットをユーザアバターに変更する。
ユーザアバターがペットから衝突離脱して一定フレーム以内に再度衝突を検知しなかったとき、視線先ターゲットをFaceComplitionに変更し、FaceComplitionはカメラの位置へと移動を開始する。
FaceComplitionがカメラと衝突すると視線先ターゲットをカメラに変更する。


%https://research.miyashita.com/2017/D174/D174.pdf

%http://archives.bukkyo-u.ac.jp/rp-contents/SO/0037/SO00370L099.pdf

%https://www.jstage.jst.go.jp/article/tvrsj/12/1/12_KJ00007499068/_pdf/-char/ja