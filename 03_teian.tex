\chapter{提案手法}
本章では，本研究で開発するバーチャルペットについて述べる．

\section{概要}

%更に、コントローラの振動機能を利用し、ユーザとバーチャルペットが接触した際に振動を起こすことで、触覚再現とまではいかずとも触ったという感覚をユーザに返すことができる。

%また、HMDを利用するとユーザの視界から現実の物や環境が遮断されることから、仮想空間内の環境もユーザに大きな影響を与えることが推測される。これはVRを利用するバーチャルペットのみに発生する特性であり、セラピー効果に関連することが考えられる。この仮想空間内の環境は開発側が任意に変更できることから、仮想空間の自由性として考える。

本研究のシステム構成図を\ref{fig:system}に示す。
本システムはHTC Vive、コントローラ、ヘッドホンから成るデバイス部とUnityにより実装したペットシステム部から構成される。

\begin{figure}[htb]
\centering
\includegraphics*[width=12cm,clip]{images/提案手法図.eps}
\caption{提案システムの構成}
\label{fig:system}
\end{figure} 


ユーザはHTC Vive、イヤホンを装着し、コントローラを手に持った状態で仮想空間に没入する。
仮想空間にはペットとユーザの２つのアバターと、環境オブジェクトが存在する。ユーザの頭部の方向はHTC Viveに、手の動きはコントローラによってトラッキングされ、仮想空間上に反映される。コントローラはトリガーもしくはボタンが入力されれば、その情報をユーザ管理プログラムへと渡す。
ユーザアバターがペットアバターとの衝突を検知すると、ユーザ管理プログラムとペット管理プログラムへそれぞれ衝突情報が渡される。ユーザ管理プログラムからはコントローラへ振動命令が出され、コントローラが振動することでユーザに接触フィードバックを起こす。
ペット管理プログラムはペットアバターのアニメーションの１つである尻尾を振る動作の再生を行い、喜びを表現する。

一連の動作を以下の図に示す。
システムを起動すると、ペットが自由に動き回る待機状態から開始する。ユーザがトリガーを深く引くと、ペットはユーザの位置まで移動し、ユーザの手前で停止する。この状態を触れ合い可能状態と呼ぶ。触れ合い可能状態では、ペットに触れることが可能になる。
この状態で再度トリガーを深く引くと、ペットは待機状態へと戻りフィールド内を自由に歩き回るようになる。

\begin{table}[htb]
\centering
\caption{スクリプト一覧}
\label{table:scriptList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|r|}
\hline
名前 & 説明 \\
\hline
PetController & ペットの動作管理 \\
PlayerController & ユーザーの動作管理 \\
MovePet & 待機状態の動作 \\
HandController & アバターの衝突検知 \\
HeadLookController & ペットの視線移動 \\
DirectionManager & ペットの視線移動における補完\\
\hline 
\end{tabular}}

\end{table}

\subsection{仮想空間}

仮想空間の構築には、Unityを使用した。

仮想空間内の環境構築にはUnityのアセットストアで提供されているNature Starter Kit 2を使用し、森林空間を表した。
更に、風を吹かせることができるWindZoneオブジェクトを配置することで、木の葉や草が揺らすように表現した。
環境音は木々のざわめきと鳥のさえずりの二種類を用意し、音量を調整した上で同時に再生した。音はループ再生する。

（仮想空間のスクリーンショット）

\subsection{ユーザ}

仮想空間に置かれるユーザのアバターは手部分のみである。HTC Viveのコントローラにはコントローラのモデルが付属しているが、現実感の低下に繋がると考える。ユーザの手のアバターをMayaを用いて作成、コントローラモデルの代わりに使用する。
ユーザの入力を表に示す。

\begin{table}[htb]
\centering
\caption{コントローラの入力一覧}
\label{table:userList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|r|}
\hline
入力 &　動作 \\
\hline
トリガーを深く引く & 待機状態と触れ合い可能状態への遷移 \\
メニューボタンを押す & 着席位置のリセット \\
グリップボタンを押す & シーンの切り替え \\
\hline 
\end{tabular}}
\end{table}

\subsection{バーチャルペット}

柴犬の子犬を参考に、バーチャルペットのモデルを作成した。
待機、歩く、走る、尻尾を振るの４種類のアニメーションが可能である。
ペットの動作を\ref{table:petList}に示す。

\begin{table}[htb]
\centering
\caption{ペットの動作一覧}
\label{table:petList}
\scalebox{1.00}{
\begin{tabular}{|c|c|r|}
\hline
動作一覧 \\
\hline
待機動作 \\
ユーザの位置へ移動\\
尻尾を振る \\
視線先変更 \\
\hline 
\end{tabular}}
\end{table}

\section{ユーザ管理部}

ユーザ管理部はPlayerControllerとHandControllerの２つのスクリプト及びSteamVRプラグインによって構成される。この設計を以下の図に示す。

HTC Vive及びコントローラの位置情報をSteamVRプラグインを利用して取得し、各ボタンの入力に応じた動作処理はPlayerControllerで行う。
コントローラのトリガーが深く引かれると、口笛の効果音を鳴らし終えた後クラス変数の代入を行う。このクラス変数の値に応じてペット管理プログラムはペットの動作処理を実行する。
コントローラのメニューボタンが押された場合はHMDの着席位置をリセットし、グリップボタンを押された場合はシーンを切り替える。このシーンの切り替えは後述する実験で使用する。
HandControllerは〜の子オブジェクトであるHandにアタッチされており、ペットアバターと衝突するとその情報を親オブジェクトであるPlayerControllerに渡す。衝突を検知するコライダーはSABoneColliderBuilderで作成した。
衝突情報を受け取ったPlayerControllerは、コントローラに振動命令を出す。HTC Viveのコントローラの振動の値は最大3999まで設定が可能だが、本研究で想定するペットに触れるという動作において強い振動は好ましくない。よって、人が振動を感知できる程度の弱い振動を求め値を200で実装した。

\section{ペット管理部}

ペット管理部はPetController、MovePet、HeadLookController、DirectionManagerの４つのスクリプトによって構成される。この設計を以下の図に示す。

PetControllerは主にペットの動作全般の制御を行う。PlayerControllerでユーザの動作に応じて代入した変数を参照し、移動、回転、視線移動、アニメーションの再生及び停止とぺットの動作を制御する。
MovePetは待機状態におけるペットの動作を制御する。待機状態でペットはまず目標位置を設定しそこへ移動を開始する。その後一定距離移動するごとに目標位置を再設定しその位置に移動、と目標位置の設定と移動を繰り返す。触れ合い状態に移行するとき、MovePetは停止する。再び待機状態に戻る際にはまた動作を再開する。
HeadLookControllerはアセットストアから入手したスクリプトで、空間内の指定されたポイントに振り向くように動作する。本研究ではペットアバターの首から頭にかけてのボーンを指定し、ｓ
DirectionManagerは

FaceComplitionはペットの視線を補完するためのオブジェクトである。このオブジェクトの動作はDirectionManagerが制御を行う。初期位置はCameraRigで、これに追従して動く。ユーザとペットが接触すると、FaceCompli



%https://research.miyashita.com/2017/D174/D174.pdf

%http://archives.bukkyo-u.ac.jp/rp-contents/SO/0037/SO00370L099.pdf

%https://www.jstage.jst.go.jp/article/tvrsj/12/1/12_KJ00007499068/_pdf/-char/ja