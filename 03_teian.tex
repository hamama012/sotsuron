\chapter{提案手法}
本章では，本研究で開発するバーチャルペットについて述べる．

\section{概要}

%更に，コントローラの振動機能を利用し，ユーザとバーチャルペットが接触した際に振動を起こすことで，触覚再現とまではいかずとも触ったという感覚をユーザに返すことができる．

%また，HMDを利用するとユーザの視界から現実の物や環境が遮断されることから，仮想空間内の環境もユーザに大きな影響を与えることが推測される．これはVRを利用するバーチャルペットのみに発生する特性であり，セラピー効果に関連することが考えられる．この仮想空間内の環境は開発側が任意に変更できることから，仮想空間の自由性として考える．

本研究のシステム構成図を図\ref{fig:design1}に示す．
本システムはHMD，コントローラ，イヤホンから成るデバイス部とUnityにより実装した仮想空間，ユーザ管理，ペット管理から成るシステム部から構成される．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design1.eps}
\caption{提案システムの構成}
\label{fig:design1}
\end{figure}

まず大まかにシステムの流れについて述べる．
ユーザはHMD，イヤホンを装着し，コントローラを手に持った状態で仮想空間に没入する．これらのデバイスを用いることによって，ユーザに視覚，聴覚，触覚への刺激を与えることが可能となる．
ユーザの頭部の動きはHMDに，手の動きはコントローラによってトラッキングされ，仮想空間上に反映される．コントローラはトリガーもしくはボタンが入力されれば，その情報をユーザ管理へと渡す．
ユーザ管理は仮想空間へボタン入力処理を行い，そのユーザ動作によってはペット管理がバーチャルペットへの行動処理を行う．
ユーザアバターがバーチャルペットとの衝突を検知すると，ユーザ管理とペット管理へそれぞれ衝突情報が渡される．
ユーザ管理からはコントローラへ振動命令が出され，コントローラが振動することでユーザに接触フィードバックを起こす．
ペット管理はバーチャルペットの衝突時における動作処理を行う．ペット管理は衝突情報の他に，位置情報など仮想空間の状況を得て処理を行う．

実際の動作の流れとして，まずペットが自由に動き回る待機状態から開始する．ユーザがトリガーを深く引くと，ペットはユーザの位置まで移動し，ユーザの手前で停止する．この状態を触れ合い可能状態と呼ぶ．触れ合い可能状態では，ペットに触れることが可能になる．
この状態で再度トリガーを深く引くと，ペットは待機状態へと戻りフィールド内を自由に歩き回るようになる．
システムのスクリーンショットを図に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/sc6.eps}
\caption{システムのスクリーンショット}
\label{fig:sc1}
\end{figure} 

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/sc7.eps}
\caption{アバター同士が衝突時のスクリーンショット}
\label{fig:sc2}
\end{figure} 

\section{仮想空間}

仮想空間の構築にはUnityを使用した．仮想空間はユーザ部，ペット部，環境部の3部から構成され，これらによって構築された仮想空間をHMDに映像として出力する．
この設計を図\ref{fig:design2}に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design2.eps}
\caption{仮想空間の詳細設計}
\label{fig:design2}
\end{figure} 

\subsection{ユーザ部}
ユーザ部はカメラ，ユーザアバターの2つのオブジェクトにより構成される．
カメラはHMDからユーザの頭部の位置情報を取得し，その動作を仮想空間に反映する．
ユーザアバターはコントローラから位置情報を取得し，カメラと同様にその動作を仮想空間に反映する．

\subsubsection{ユーザアバター}
仮想空間に置かれるユーザのアバターは手部分のみである．HMDのコントローラにはコントローラの3DCGモデルが標準で用意されているが，現実感の付与を目的とした本研究ではコントローラよりも人間の手のモデルを使用した方が自然である．そのためMayaを用いて手の3DCGを作成し，Unityへエクスポートした．コントローラモデルの代わりに使用する．物理衝突による処理を行うため，コライダーと呼ばれるコンポーネントを用いて物理衝突のためのオブジェクト形状を定義する．
ユーザアバターのコライダーはアセットストアから入手したSAColliderBuilderを使用して可能な限り精密なものを作成した．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/hand.eps}
\caption{ユーザアバターの3DCGモデル}
\label{fig:hand}
\end{figure} 

\subsection{ペット部}
ペット部はバーチャルペット，視線補完オブジェクトの2つのオブジェクトにより構成される．
バーチャルペットはペット管理に位置情報，衝突情報といった仮想空間におけるアバターの状況を渡し，その状況に応じた行動処理を受け仮想空間上で動作する．
視線補完オブジェクトはバーチャルペットの視線移動をスムーズに行うために用意されたオブジェクトである．
バーチャルペットと同様に，ペット管理に位置情報，衝突情報といった仮想空間におけるオブジェクトの状況を渡し，その状況に応じた行動処理を受け仮想空間上で動作する．

\subsubsection{バーチャルペット}
本研究では先行研究のバーチャルペットは使用せず，新しく柴犬の子犬を参考にMayaを用いて3DCGモデルを作成，Unityへエクスポートした．待機，歩く，走る，尻尾を振るの4種類のアニメーションが可能である．コライダーはユーザアバターと同様に，アセットストアから入手したSAColliderBuilderを使用して可能な限り精密なものを作成した．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/pet.eps}
\caption{バーチャルペットの3DCGモデル}
\label{fig:pet}
\end{figure} 

\subsection{環境部}
環境部はオーディオ，木や草などの環境を構築する複数の環境オブジェクトから構成される．
木や草，地面などの環境オブジェクトはUnityのアセットストアで入手したNature Starter Kit 2を使用して配置した．
更に，風を吹かせることができるWindZoneを環境オブジェクトとして配置することで，木の葉や草が揺れるように表現した．
環境音は木々のざわめきと鳥のさえずりの二種類を用意し，音量を調整した上で同時に再生し，デバイスであるイヤホンに出力する．音はループ再生する．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/sc8.eps}
\caption{仮想空間}
\label{fig:vr}
\end{figure} 

\section{ユーザ管理}

ユーザ管理はPlayerControllerとHandControllerの2つのスクリプトによって構成される．
この設計を図\ref{fig:design3}に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design3.eps}
\caption{ユーザ管理の詳細設計}
\label{fig:design3}
\end{figure}

PlayerControllerはコントローラのボタン入力に対し，各ボタンの入力に応じた動作処理を行う．
コントローラのトリガーが深く引かれると，口笛の効果音を鳴らし終えた後にpublicで宣言した変数の代入を行う．この変数の値に応じてペット管理はペットの動作処理を実行する．
コントローラのメニューボタンが押された場合はHMDの位置を初期位置へとリセットし，グリップボタンを押された場合はシーンを切り替える．このシーンの切り替えは後述する実験で使用する．
以上のコントローラの入力を表\ref{table:userList}に示す．

\begin{table}[H]
\centering
\caption{コントローラの入力一覧}
\label{table:userList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|l|}
\hline
入力 &　動作 \\
\hline
トリガーを深く引く & 待機状態もしくは触れ合い可能状態への遷移 \\
メニューボタンを押す & 着席位置のリセット \\
グリップボタンを押す & シーンの切り替え \\
\hline 
\end{tabular}}
\end{table}

HandControllerはユーザアバターにアタッチされており，バーチャルペットと衝突するとその情報を親オブジェクトにアタッチされているPlayerControllerに渡す．衝突情報を受け取ったPlayerControllerは，コントローラに振動命令を出す．

HMDのコントローラの振動の値は最大3999まで設定が可能だが，本研究で想定するペットに触れるという動作において強い振動は好ましくない．
よって，人が感知できる程度の弱い振動を求め値を200で実装した．

\section{ペット管理}

ペット管理はPetController，MovePet，HeadLookController，DirectionManagerの４つのスクリプトによって構成される．
この設計を図\ref{fig:design4}に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design4.eps}
\caption{ペット管理の詳細設計}
\label{fig:design4}
\end{figure}

PetControllerは主にペットの触れ合い可能状態における動作処理を行うスクリプトである．
システムは起動時待機状態で開始するが，コントローラのトリガーが深く引かれるとPlayerControllerが変数を代入する．この変数を参照し，PetControllerは触れ合い可能状態への移行を開始する．
触れ合い可能状態へ移行するにあたり，待機状態の動作を制御するMovePetを停止し，代わりに視線動作を制御するHeadLookControllerの動作を開始する．
口笛が鳴り終えると，バーチャルペットは走るアニメーションを再生すると共にユーザの位置へと移動を開始し，ユーザの手前で停止する．
このとき自然な動作が行えるように回転の動きは球面線形補完を行うSlerp関数を用いて記述した．
この状態で再度トリガーが深く引かれると，MovePetを起動すると共にHeadLookControllerを停止し，待機状態へと戻る．
ユーザアバターと衝突すると，尻尾を振るアニメーションを再生し，視線先を変更すると共に衝突カウントを始める．
衝突カウントは初期値0で，衝突後1フレームごとに1増加し，一定数を超えると0へとリセットされる．この間，バーチャルペットは衝突時の処理を行わない．再度衝突するとまたカウントを開始する．
衝突から離脱，すなわちユーザアバターがバーチャルペットから離れたとき，離脱カウントが開始する．
離脱カウントは初期値0で，衝突後1フレームごとに1増加し，一定数を超えると0へとリセットされる．この間，バーチャルペットに再度衝突しても0にリセットされる．
一定数を超えたとき，尻尾を振る動作を停止すると共に視線先ターゲットを変更する．

MovePetは待機状態の動作処理を行うスクリプトである．
目標位置を設定し，その位置に向かってバーチャルペットの移動を行う．
一定距離移動すると目標位置を設定し直し，その新しく設定した目標位置へと移動する．
この動作を待機状態の間繰り返す．
前述したように，このスクリプトは触れ合い可能状態へ移行する際にPetControllerによって停止し，待機状態へ移行する際に起動する．

HeadLookControllerはアセットストアから入手したスクリプトで，動かしたい部分のボーンを指定してそのボーンのみを動かす．
このスクリプトを利用して視線移動を行う．
前述したように，このスクリプトは触れ合い可能状態へ移行する際にPetControllerによって起動し，待機状態へ移行する際に停止する．
HeadLookControllerスクリプトのインスペクターを図\ref{fig:headlook}に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=11cm,clip]{images/sc9.eps}
\caption{HeadLookControllerのインスペクター}
\label{fig:headlook}
\end{figure}

動かすボーンの指定はSegments下のElement0で行った．バーチャルペットの首から頭頂部までにあたるボーンNeck1からボーンHeadまでのボーンを指定し，その部分のみを動かす．各パラメータの説明を述べる．
Threshold Angle Differenceはターゲットとバーチャルペットの角度がここで指定した角度よりも大きいとき，ターゲットの方に回転し始める閾値となる角度である．
Bending Multiplierはターゲットとの角度の大きさと比較して指定したボーンがどのくらい大きく動くかを表す値である．
Max Angle Differenceはターゲットとの角度がこの値よりも大きくならないよう保持する．しかし，Max Bending Angleで設定した値に達したときはそれ以上動かない．
Responsivenessはターゲットを追う速度の値である．バーチャルペットの動きが出来る限り自然になるよう各値を設定した．LookTargetは視線先ターゲットを指す．

DirectionManagerはバーチャルペットの視線移動をスムーズに行うために視線補完オブジェクトFaceComplitionの動作処理を行うスクリプトである．
FaceComplitionの初期位置はカメラで，カメラに追従して動く．
バーチャルペットとユーザアバターが接触すると，移動先をユーザアバターに設定し移動を開始する．
このとき視線先ターゲットをFaceComplitionに指定することで，バーチャルペットはFaceComplitionに視線を向ける．
ユーザアバターと接触すると，視線先ターゲットをユーザアバターに設定し，その後はユーザアバターに追従して移動する．
ユーザアバターが衝突離脱して一定フレーム経過すると次の移動先をカメラに設定し移動を開始し，前述した処理と同様に視線先ターゲットをFaceComplitionに設定し，カメラと衝突すると視線先ターゲットをカメラに設定する．
その後はカメラに追従して移動する．
バーチャルペットの動作のフローチャートを図\ref{fig:chart1}に示す．

\begin{figure}[H]
\centering
\includegraphics*[width=16cm,clip]{images/chart1.eps}
\caption{バーチャルペットの動作のフローチャート}
\label{fig:chart1}
\end{figure} 


%https://research.miyashita.com/2017/D174/D174.pdf

%http://archives.bukkyo-u.ac.jp/rp-contents/SO/0037/SO00370L099.pdf

%https://www.jstage.jst.go.jp/article/tvrsj/12/1/12_KJ00007499068/_pdf/-char/ja