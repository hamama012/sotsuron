\chapter{提案手法}
本章では，本研究で開発するバーチャルペットについて述べる．

\section{概要}

%更に、コントローラの振動機能を利用し、ユーザとバーチャルペットが接触した際に振動を起こすことで、触覚再現とまではいかずとも触ったという感覚をユーザに返すことができる。

%また、HMDを利用するとユーザの視界から現実の物や環境が遮断されることから、仮想空間内の環境もユーザに大きな影響を与えることが推測される。これはVRを利用するバーチャルペットのみに発生する特性であり、セラピー効果に関連することが考えられる。この仮想空間内の環境は開発側が任意に変更できることから、仮想空間の自由性として考える。

本研究のシステム構成図を図\ref{fig:design1}に示す。
本システムはHMD、コントローラ、ヘッドホンから成るデバイス部とUnityにより実装したペットシステム部から構成される。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design1.eps}
\caption{提案システムの構成}
\label{fig:design1}
\end{figure}

ユーザはHMD、イヤホンを装着し、コントローラを手に持った状態で仮想空間に没入する。
仮想空間にはペットとユーザの２つのアバターと、環境オブジェクトが存在する。ユーザの頭部の方向はHMDに、手の動きはコントローラによってトラッキングされ、仮想空間上に反映される。コントローラはトリガーもしくはボタンが入力されれば、その情報をユーザ管理プログラムへと渡す。
ユーザアバターがペットアバターとの衝突を検知すると、ユーザ管理プログラムとペット管理プログラムへそれぞれ衝突情報が渡される。ユーザ管理プログラムからはコントローラへ振動命令が出され、コントローラが振動することでユーザに接触フィードバックを起こす。
ペット管理プログラムはペットアバターのアニメーションの１つである尻尾を振る動作の再生を行い、喜びを表現する。

システムを起動すると、ペットが自由に動き回る待機状態から開始する。ユーザがトリガーを深く引くと、ペットはユーザの位置まで移動し、ユーザの手前で停止する。この状態を触れ合い可能状態と呼ぶ。触れ合い可能状態では、ペットに触れることが可能になる。
この状態で再度トリガーを深く引くと、ペットは待機状態へと戻りフィールド内を自由に歩き回るようになる。

\subsection{仮想空間}

仮想空間の構築にはUnityを使用した。仮想空間はユーザ部、ペット部、環境オブジェクトから成る。
この設計を図\ref{fig:design2}に示す。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design2.eps}
\caption{仮想空間の詳細設計}
\label{fig:design2}
\end{figure} 

ユーザ部はカメラ、ユーザアバターの２つのオブジェクトにより構成される。
カメラはHMDからユーザの頭部の位置情報を取得し、その動作を仮想空間に反映する。
ユーザアバターはコントローラから位置情報を取得し、カメラと同様にその動作を仮想空間に反映する。
ペット部はペットアバター、視線補完オブジェクトの２つのオブジェクトにより構成される。
ペットアバターはペット管理部に位置情報、衝突情報といった仮想空間におけるアバターの状況を渡し、その状況に応じた行動処理を受け仮想空間上で動作する。
視線補完オブジェクトはペットの視線移動を自然に行うために用意されたオブジェクトである。
ペットアバターと同様に、ペット管理部に位置情報、衝突情報といった仮想空間におけるアバターの状況を渡し、その状況に応じた行動処理を受け仮想空間上で動作する。

環境オブジェクトは環境を構築する全てのオブジェクトを格納する。
木や草などのオブジェクトはUnityのアセットストアで入手したNature Starter Kit 2を使用して配置した。
更に、風を吹かせることができるWindZoneオブジェクトを配置することで、木の葉や草が揺らすように表現した。
環境音は木々のざわめきと鳥のさえずりの二種類を用意し、音量を調整した上で同時に再生した。音はループ再生する。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/sc8.eps}
\caption{仮想空間}
\label{fig:vr}
\end{figure} 

\subsection{ユーザ}

仮想空間に置かれるユーザのアバターは手部分のみである。HMDのコントローラにはコントローラの3DCGモデルが標準で用意されているが、現実感の付与を目的とした本研究ではコントローラよりも人間の手のモデルを使用した方が自然である。そのためMayaを用いて手の3DCGを作成し、Unityへエクスポートした。コントローラモデルの代わりに使用する。コライダーはアセットストアから入手したSABoneColiderを使用して可能な限り精密なものを作成した。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/hand.eps}
\caption{ユーザアバター}
\label{fig:hand}
\end{figure} 

\subsection{バーチャルペット}

本研究では先行研究のバーチャルペットは使用せず、新しく柴犬を参考にMayaを用いて3DCGモデルを作成、Unityへエクスポートした。待機、歩く、走る、尻尾を振るの４種類のアニメーションが可能である。コライダーはユーザアバターと同様に、アセットストアから入手したSABoneColiderを使用して可能な限り精密なものを作成した。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/pet.eps}
\caption{バーチャルペットのアバター}
\label{fig:pet}
\end{figure} 

\section{ユーザ管理部}

ユーザ管理部はPlayerControllerとHandControllerの２つのスクリプトによって構成される。
この設計を図\ref{fig:design3}に示す。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design3.eps}
\caption{提案システムの構成}
\label{fig:design3}
\end{figure}

PlayerControllerはコントローラのボタン入力に対し、各ボタンの入力に応じた動作処理を行う。
コントローラのトリガーが深く引かれると、口笛の効果音を鳴らし終えた後クラス変数の代入を行う。このクラス変数の値に応じてペット管理プログラムはペットの動作処理を実行する。
コントローラのメニューボタンが押された場合はHMDの位置を初期位置へとリセットし、グリップボタンを押された場合はシーンを切り替える。このシーンの切り替えは後述する実験で使用する。
以上のコントローラの入力を表\ref{table:userList}に示す。

\begin{table}[H]
\centering
\caption{コントローラの入力一覧}
\label{table:userList}
\scalebox{1.00}{
\begin{tabular}{|c||c|l|c|l|}
\hline
入力 &　動作 \\
\hline
トリガーを深く引く & 待機状態と触れ合い可能状態への遷移 \\
メニューボタンを押す & 着席位置のリセット \\
グリップボタンを押す & シーンの切り替え \\
\hline 
\end{tabular}}
\end{table}

HMD及びコントローラの位置情報をSteamVRプラグインを利用して取得し、各ボタンの入力に応じた動作処理はPlayerControllerで行う。
コントローラのトリガーが深く引かれると、口笛の効果音を鳴らし終えた後クラス変数の代入を行う。このクラス変数の値に応じてペット管理プログラムはペットの動作処理を実行する。
コントローラのメニューボタンが押された場合はHMDの着席位置をリセットし、グリップボタンを押された場合はシーンを切り替える。このシーンの切り替えは後述する実験で使用する。
HandControllerはユーザアバターにアタッチされており、ペットアバターと衝突するとその情報を親オブジェクトであるPlayerControllerに渡す。
衝突情報を受け取ったPlayerControllerは、コントローラに振動命令を出す。HMDのコントローラの振動の値は最大3999まで設定が可能だが、本研究で想定するペットに触れるという動作において強い振動は好ましくない。よって、人が振動を感知できる程度の弱い振動を求め値を200で実装した。

\section{ペット管理部}

ペット管理部はPetController、MovePet、HeadLookController、DirectionManagerの４つのスクリプトによって構成される。
この設計を図\ref{fig:design4}に示す。

\begin{figure}[H]
\centering
\includegraphics*[width=15cm,clip]{images/design4.eps}
\caption{提案システムの構成}
\label{fig:design4}
\end{figure}

PetControllerは主にペットの触れ合い可能状態における動作処理を行う。
システムは起動時待機状態で開始するが、コントローラトリガーが深く引かれると
PlayerControllerの変数を参照して
PlayerControllerでユーザの動作に応じて代入した変数を参照し、また仮想空間の状況に応じて移動、回転、視線移動、アニメーションの再生及び停止とぺットの動作を制御する。
MovePetは待機状態におけるペットの動作を制御する。待機状態でペットはまず目標位置を設定しそこへ移動を開始する。その後一定距離移動するごとに目標位置を再設定し、その位置に移動と目標位置の設定と移動を繰り返す。触れ合い状態に移行するとき、MovePetは停止する。再び待機状態に戻る際にはまた動作を再開する。
HeadLookControllerはアセットストアから入手したスクリプトで、動かしたい部分のボーンを指定してその部分のみを空間内の指定されたターゲットに振り向くように動動かす。本研究ではペットアバターの首から頭にかけてのボーンを指定し動作させる。
DirectionManagerはペットの視線移動を補完するためのオブジェクトであるFaceComplitionの動作を制御する。
FaceComplitionの初期位置はカメラで、これに追従して動く。ユーザとペットが衝突すると、視線先ターゲットをFaceComplitionに変更し、FaceComplitionはユーザアバターの位置へと移動を開始する。
FaceComplitionがユーザアバターに衝突すると、視線先ターゲットをユーザアバターに変更する。
ユーザアバターがペットから衝突離脱して一定フレーム以内に再度衝突を検知しなかったとき、視線先ターゲットをFaceComplitionに変更し、FaceComplitionはカメラの位置へと移動を開始する。
FaceComplitionがカメラと衝突すると視線先ターゲットをカメラに変更する。
ペットの動作のフローチャートを\ref{fig:chart1}に示す。

\begin{figure}[H]
\centering
\includegraphics*[width=16cm,clip]{images/chart1.eps}
\caption{ペットの動作のフローチャート}
\label{fig:chart1}
\end{figure} 


%https://research.miyashita.com/2017/D174/D174.pdf

%http://archives.bukkyo-u.ac.jp/rp-contents/SO/0037/SO00370L099.pdf

%https://www.jstage.jst.go.jp/article/tvrsj/12/1/12_KJ00007499068/_pdf/-char/ja